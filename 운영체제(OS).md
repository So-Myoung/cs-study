<h3>1. 시스템 콜이 무엇인지 설명해 주세요.</h3>

```
운영체제의 커널이 제공하는 서비스에 대해 
응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스
```
<ul>
<li> 우리가 사용하는 시스템 콜의 예시를 들어주세요.</li>

```c
// 파일 조작 시스템 콜
open(): 파일 열기
read(): 파일 읽기
write(): 파일 쓰기
close(): 파일 닫기

// 프로세스 관리 시스템 콜
fork(): 새로운 프로세스 생성
exec(): 새로운 프로세스 실행
exit(): 프로세스 종료
wait(): 자식 프로세스 종료 대기

// 메모리 관리 시스템 콜
brk(), sbrk(): 힙 영역 크기 변경
mmap(), munmap(): 메모리 매핑 및 해제
```
<li> 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.</li>

```
사용자 프로그램 실행 중 시스템 콜 요청 -> 커널 모드 전환 -> 
해당 시스템 콜 핸들러 실행 -> 커널 작업 수행 후 결과 반환 -> 사용자 모드 복귀
```

<li> 시스템 콜의 유형에 대해 설명해 주세요.</li>

```
1. 프로세스 제어(process control)
2. 파일 조작(file manipulation)
3. 장치 관리(device management)
4. 정보 유지(information maintenance)
5. 통신(communication)
```
<li> 운영체제의 Dual Mode 에 대해 설명해 주세요.</li>

```
1. 사용자 모드(User Mode)
- 일반 응용 프로그램이 실행되는 모드
- 사용자가 접근할 수 있는 영역에 제한이 있기 때문에 해당 모드에서는 하드웨어에 접근할 수 없음
2. 커널 모드(Kernel Mode)
- 시스템 콜을 처리하고 메모리 관리, 프로세스 스케줄링 등을 수행
- 운영체제가 하드웨어와 직접 상호작용
```
<li> 왜 사용자모드와 커널모드를 구분해야 하나요? </li>

```
보안(Security), 안정성(Stability), 자원 관리(Resource Management)
사용자 프로그램이 하드웨어 자원에 직접 접근하는 것을 방지하고, 
운영체제를 통해 안전하게 자원을 사용할 수 있도록 하기 위해서
```
<li> 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?</li>

```c
고유한 시스템 콜 번호를 통해 구분
ex)
read() : 0x03
write() : 0x04
-> 운영체제는 시스템 콜 테이블(System Call Table)에서 
시스템 콜 번호를 확인한 후 적절한 핸들러를 실행
```
</ul>

<h3>2. 인터럽트가 무엇인지 설명해 주세요.</h3>

```
CPU가 현재 실행 중인 작업을 중단하고, 
특정 이벤트를 우선적으로 처리하도록 하는 메커니즘
```
<ul>
<li> 인터럽트는 어떻게 처리하나요?</li>

```
인터럽트 발생 -> 현재 작업 저장 -> 인터럽트 핸들러(ISR) 실행
이전 상태 복구 -> 원래 작업 복귀
```
** 인터럽트가 너무 자주 발생하면 CPU가 계속 인터럽트를 처리해야 하므로, 
원래 수행 중이던 작업이 무기한 지연되어 기아 상태(Starvation)가 발생

<li> Polling 방식에 대해 설명해 주세요.</li>

```
CPU가 주기적으로 장치를 검사하여 일정한 조건이 만족되었 때 
송수신 등의 자료처리를 하는 방식
```
| 항목 | Polling | Interrupt |
|------|---------|----------|
| 처리 방식 | CPU가 주기적으로 상태를 검사 | 이벤트 발생 시 CPU에 알림 |
| CPU 자원 사용 | 높음 | 낮음 |
| 응답 속도 | 느림 | 빠름 |
| 주 사용처 | 간단한 시스템 | 복잡한 OS, 멀티태스킹 환경 |

<li> HW / SW 인터럽트에 대해 설명해 주세요.</li>

```
1. 하드웨어 인터럽트 (Hardware Interrupt)
- 외부 장치에서 발생하는 인터럽트
- 하드웨어 컨트롤러가 CPU에 직접 인터럽트 신호를 보냄
- 비동기적으로 발생
2. 소프트웨어 인터럽트 (Software Interrupt)
- 소프트웨어가 실행 도중 명령어를 통해 직접 발생시키는 인터럽트
- 시스템 콜(System Call)과 같은 OS 기능을 사용할 때 주로 사용
- 동기적으로 발생
```

<li> 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요? </li>

```
- 우선순위(Priority) 기반 처리
하드웨어적으로 인터럽트의 우선순위를 정하고, 우선순위가 높은 인터럽트를 먼저 처리
```
__Nested Interrupt (중첩 인터럽트)__
```
인터럽트 처리 중 더 높은 우선순위의 인터럽트가 발생하면, 
기존 인터럽트 처리를 중단하고 새로운 인터럽트를 처리한 후, 
다시 원래 인터럽트 처리를 이어감.
```
__Interrupt Masking(인터럽트 마스킹)__
```
특정 인터럽트를 일시적으로 비활성화하여, 
현재 실행 중인 인터럽트가 끝날 때까지 
새로운 인터럽트가 발생하지 않도록 막음.
```
</ul>

<h3>3. 프로세스가 무엇인가요?</h3>

```
컴퓨터에서 연속적으로 실행되고 있는 프로그램
프로그램이 메모리 상에서 실행되는 작업 단위
```
<ul>
<li> 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.</li>

```
프로그램: 일반적으로 하드 디스크 등에 저장되어 있는 실행코드, 실행 가능한 정적인 코드 자체
프로세스: 프로그램이 메모리 상에서 실행되는 작업 단위, 실행 중인 프로그램
스레드: 프로세스 내에서 실행되는 흐름의 단위
```
![image](https://github.com/user-attachments/assets/111daa68-7643-4d6f-8eb7-f525cd96d677)

<li> PCB가 무엇인가요?</li>

```
Process Control Block
운영체제가 프로세스를 관리하기 위해 각 프로세스마다 존재하는 구조체
프로세스의 중요한 정보를 저장하며, 운영체제의 커널 영역에 존재
```
```
1. PID (프로세스 ID): 프로세스를 구별하는 고유한 ID.
2. 프로세스 상태: 실행(Running), 대기(Waiting), 종료(Terminated) 등의 상태 정보.
3. 레지스터 정보: 프로세스의 CPU 실행 상태.
4. 메모리 정보: 코드, 데이터, 스택, 힙 영역의 위치.
5. 파일 디스크립터: 프로세스가 열어둔 파일 정보.
6. 스케줄링 정보: 프로세스 우선순위 및 스케줄링 큐 위치.
```
<li> 그렇다면, 스레드는 PCB를 갖고 있을까요?</li>

```
스레드는 독립적인 PCB를 가지고 있지 않지만,
TCB(Thread Control Block) 존재
```
<li> 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?</li>

```c
프로세스: fork() 시스템 콜을 사용하여 부모 프로세스의 복제본을 생성
스레드 : pthread_create()를 사용하여 같은 프로세스 내에서 새로운 실행 흐름을 생성.
하지만 많은 스레드를 생성하면 컨텍스트 스위칭(Context Switching) 오버헤드(Overhead)와 리소스 낭비가 발생할 수 있음.  
이를 해결하기 위해 스레드 풀(Thread Pool)을 사용하면, 미리 생성된 스레드를 재사용하여 자원 관리 효율성을 높일 수 있음.
** 컨텍스트 스위칭(Context Switching): CPU가 실행 중인 프로세스 또는 스레드를 전환할 때 발생하는 비용
```
<li> 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?</li>

```
- 자식 프로세스가 상태를 알리지 않고 종료될 경우
자식 프로세스의 PCB(Process Control Block)는 커널에 남아 좀비 프로세스(Zombie Process)가 됨.
자식 프로세스가 종료되면 부모 프로세스가 wait() 또는 waitpid() 시스템 콜을 호출하여 종료 상태를 수거해야 함.
- 부모 프로세스가 먼저 종료될 경우
부모가 먼저 종료되면, 자식 프로세스는 고아 프로세스(Orphan Process)가 됨
리눅스에서는 고아 프로세스를 init(PID 1) 프로세스가 자동으로 수거하여 정상적으로 실행되도록 함
```

<li> 리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.</li>

```
init(PID 1) 프로세스
- 시스템 부팅 시 가장 먼저 실행되는 프로세스
- 모든 프로세스의 부모 역할을 수행
- 고아 프로세스 관리(부모가 없는 프로세스의 새로운 부모 노드가 됨)
- 좀비 프로세스를 정리
```
<li> 리눅스에서, 데몬프로세스에 대해 설명해 주세요.</li>

```
백그라운드에서 실행되며 특정 시스템 서비스를 제공하는 독립적인 프로세스
```
</ul>

<h3>4. 프로세스 주소공간에 대해 설명해 주세요.</h3>

```
1. 코드 영역 (Text Section): 실행 코드가 저장되는 영역
2. 데이터 영역 (Data Section): 전역 변수 및 정적 변수 저장
3. 힙 영역 (Heap Section): 동적 메모리 할당 시 사용되는 영역
4. 스택 영역 (Stack Section): 함수 호출 및 지역 변수 저장
```
<ul>
<li> 초기화 하지 않은 변수들은 어디에 저장될까요?</li>

```
초기화되지 않은 변수는 BSS (Block Started by Symbol) 영역에 저장
초기화된 변수는 데이터(Data) 영역에 저장
```
<li> 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?</li>

```
Stack
- 기본적으로 작게 할당
- 함수가 호출될 때, 해당 함수의 지역 변수 크기만큼 스택이 증가하고, 호출이 끝나면 해제
- 스택의 최대 크기는 OS 설정에 따라 제한
Heap
-  Heap 크기는 프로세스 실행 중 동적으로 변하며, 사용자의 요청에 따라 증가 가능하지만, 줄어드는 것은 제한적
- OS가 관리하며, 특정 크기 이상이 되면 sbrk(), mmap() 등을 통해 메모리 영역을 확장.
- free() 또는 delete를 호출하면 메모리가 해제되지만, Heap 크기가 자동으로 줄어들지는 않음.
```
<li> Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?</li>

__Stack__
```
스택은 연속적인 메모리 공간에 저장되어 캐시 지역성(Cache Locality)이 뛰어남
Heap은 메모리 블록 검색이 필요하여 할당/해제 속도가 상대적으로 느림.
```                                             
<li> 다음과 같이 공간을 분할하는 이유가 있을까요?</li>

```
1. 메모리 보호 및 보안
- Stack과 Heap이 분리되지 않으면, Overflow로 인해 다른 영역을 침범할 위험
2. 효율적인 메모리 관리
- Stack과 Heap은 사용 목적이 다르므로, 효율적인 메모리 관리를 위해 분리
3. 프로세스 간 메모리 충돌 방지
- 같은 주소를 사용하더라도, 각 프로세스의 메모리는 독립적
```
<li> 스레드의 주소공간은 어떻게 구성되어 있을까요?</li>

```
스레드는 코드, 데이터, 힙 영역을 공유하지만 각 스레드마다 독립적인 스택(Stack) 공간을 가짐
```
<li> "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.</li>

```
스택(Stack) 영역
- 자료구조 Stack과 유사 (LIFO 구조)
- 함수 호출 시 Push, 리턴 시 Pop.
힙(Heap) 영역
- 자료구조 Heap과 관계 없음.
- 동적 메모리 할당을 위해 존재하는 공간
```
<li> IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요? </li>

![image](https://github.com/user-attachments/assets/9786983d-56d4-46aa-90cd-fa648ec0410f)

```
IPC(Inter-Process Communication, 프로세스 간 통신)에서 
Shared Memory(공유 메모리)는 일반적으로 Heap 또는 mmap을 통해 특정 메모리 영역에 할당
프로세스 간 데이터를 빠르게 주고 받을 수 있음
**  공유 메모리(Shared Memory)
하나의 프로세스에서 할당한 메모리 영역을 다른 프로세스와 공유하여 사용할 수 있는 기법
가장 빠른 IPC 방법 중 하나
메시지 큐, 파이프, 소켓과 비교하여 속도가 빠름
```
<li> 스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요? </li>

```
Stack
- 스택(Stack) 크기는 실행 중 변경할 수 없으며, 프로그램이 실행되기 전에만 크기 설정 가능
- 리눅스에서 ulimit -s로 변경할 수 있으며, 실행 전에 설정 해야함 
Heap
- malloc(), sbrk(), mmap()을 통해 동적으로 크기 변경 가능
- 일반 사용자는 ulimit, /etc/security/limits.conf 설정을 변경하여 조절 가능
ulimit -s <크기>로 스택 크기 조정 가능
ulimit -d <크기>로 데이터 영역(힙 포함) 크기 조정 가능
```
</ul>

<h3>5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.</h3>

```
운영체제(OS)에서 프로세스의 실행을 관리하기 위해 스케줄러(Scheduler) 사용

장기 스케줄러 (Long-term Scheduler)
- 프로세스를 디스크에서 메모리로 로드하는 역할
- 새롭게 실행할 프로세스를 선택해서 실행 준비
중기 스케줄러 (Mid-term Scheduler)
- 중기 스케줄러는 실행 중인 프로세스를 메모리에서 디스크로 내보내거나, 다시 불러오는 역할
- 이 과정은 스와핑(Swapping)이라고 하며, 메모리를 확보하기 위해 사용
단기 스케줄러 (Short-term Scheduler, CPU Scheduler)
- 단기 스케줄러는 Ready 상태에서 대기 중인 프로세스 중 하나를 선택하여 CPU를 할당하는 역할
- 다음에 실행할 프로세스를 정하는 것이 단기 스케줄러의 역할
```
<ul>
<li> 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?</li>

```
장기 스케줄러: 현대 OS에서 사용하지 않는 경우가 많음
중기 스케줄러: 특정 환경에서 존재
- 페이징(Paging) 기법을 주로 사용하지만 여전히 일부 시스템에서는 스와핑을 활용하여 메모리를 관리
단기 스케줄러: 반드시 존재
- CPU 스케줄링을 수행하는 핵심 요소
```
<li> 프로세스의 스케쥴링 상태에 대해 설명해 주세요.</li>

```
1. New (생성)
프로세스가 생성되었지만 아직 OS에 의해 준비 상태로 옮겨지지 않은 상태
2. Ready (준비)
실행할 준비가 된 상태이며, CPU를 할당받기를 기다리는 상태
단기 스케줄러가 Ready Queue에서 프로세스를 선택하여 CPU에 할당
3. Running (실행)
현재 CPU에서 실행 중인 상태
단기 스케줄러가 CPU를 할당하면 Ready 상태에서 Running 상태로 전환
4. Waiting (대기)
프로세스가 입출력(I/O) 작업 등으로 인해 CPU를 사용하지 못하고 기다리는 상태
I/O 작업이 끝나면 다시 Ready 상태로 복귀
5. Terminated (종료)
프로세스 실행이 완료되거나, 강제 종료된 상태
추가 상태:
Suspended(일시 정지): 중기 스케줄러가 프로세스를 스와핑할 때 발생하는 상태
Suspended Ready: 메모리에서 디스크로 스와핑되었지만, 다시 실행 가능
Suspended Waiting: 대기 중이지만 메모리에서 제거
```
<li> preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?</li>

```
선점형(Preemptive) 스케줄링
- 운영체제가 실행 중인 프로세스를 강제로 중단시키고, 다른 프로세스로 CPU를 재할당할 수 있는 방식
- 실행 중인 프로세스가 강제로 중단되어 Running → Ready 상태로 전환될 수 있음
비선점형(Preemptive) 스케줄링
- 한 번 CPU를 할당받으면, 프로세스가 스스로 종료하거나 I/O 작업을 수행할 때까지 계속 실행하는 방식
- Running → Ready 상태가 발생하지 않음
- 한 프로세스가 실행되면 끝날 때까지 CPU를 독점
```
<li> Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?</li>

```
1. Blocked → Suspended Waiting
- I/O 요청을 대기하는 프로세스가 메모리에서 디스크로 이동 (Swap-out)
- I/O가 끝나도 메모리가 부족하면 Ready 상태로 이동하지 못함
2. Ready → Suspended Ready
- 그래도 메모리가 부족하면 실행 대기(Ready) 중인 프로세스를 스왑 아웃 (Swap-out)
- 메모리가 확보되면 다시 Ready 상태로 복귀
3. Running → Waiting (페이지 폴트 발생 시)
실행 중인 프로세스가 참조하려는 페이지가 RAM에 없어서 디스크에서 로드해야 하는 경우
```
</ul>
